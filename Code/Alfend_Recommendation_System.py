# -*- coding: utf-8 -*-
"""Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l-WrsFbVatmWxSA30Din7bQxCZz4Uqnm

# Recommendation System using Restaurant and Consumer Dataset

# Alfendio Alif Faudisyah

# Data Understanding

## Download dataset
"""

!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00232/RCdata.zip

"""## Unzip file """

!unzip /content/RCdata.zip

""" ## Baca data menggunakan fungsi pandas.read_csv"""

import pandas as pd
 
accepts = pd.read_csv('/content/chefmozaccepts.csv')
cuisine = pd.read_csv('/content/chefmozcuisine.csv')
hours = pd.read_csv('/content/chefmozhours4.csv')
parking = pd.read_csv('/content/chefmozparking.csv')
geo = pd.read_csv('/content/geoplaces2.csv', encoding = "ISO-8859-1")
usercuisine = pd.read_csv('/content/usercuisine.csv')
payment = pd.read_csv('/content/userpayment.csv')
profile = pd.read_csv('/content/userprofile.csv')
rating = pd.read_csv('/content/rating_final.csv')
 
print('Jumlah data pembayaran yang diterima restoran: ', len(accepts.placeID.unique()))
print('Jumlah data masakan pada restoran: ', len(cuisine.placeID.unique()))
print('Jumlah data waktu buka restoran: ', len(hours.placeID.unique()))
print('Jumlah data lokasi restoran: ', len(geo.placeID.unique()))
print('Jumlah data masakan pengguna: ', len(usercuisine.userID.unique()))
print('Jumlah data profil pengguna: ', len(profile.userID.unique()))
print('Jumlah data penilaian yang diberikan pengguna: ', len(rating.userID.unique()))
print('Jumlah data penilaian restoran: ', len(rating.placeID.unique()))

"""# Univariate Exploratory Data Analysis

Variabel-variabel pada Restaurant UCI dataset adalah:

- accepts : merupakan jenis pembayaran yang diterima pada restoran tertentu.
- cuisine : merupakan jenis masakan yang disajikan pada restoran.
- hours : merupakan jadwal buka dan tutupnya restoran.
- parking : merupakan ketersediaan tempat parkir pada restoran.
- geo : merupakan letak restoran.
- usercuisine : merupakan jenis masakan dari data pengguna.
- payment : merupakan jenis pembayaran yang dipakai pengguna.
- profile : merupakan data profil pengguna.

Variabel cuisine dan rating akan digunakan pada model rekomendasi. Variabel accept dan profile digunakan untuk melihat bagaimana profil dan jenis pembayaran yang digunakan oleh pengguna.

## Accept Variabel
"""

accepts.info()

"""- File accept.csv memiliki 1314 entri.
- Accepts termasuk ke dalam kategori data Restaurant.
- Terdapat dua variabel, PlaceID merupakan ID restoran, Rpayment merupakan jenis pembayaran yang digunakan pada restoran.

Lihat ada berapa banyak entri yang unik berdasarkan placeID dan jenis-jenis pembayaran unik yang diterima
"""

print('Banyak data: ', len(accepts.placeID.unique()))
print('Jenis Pembayaran yang diterima: ', accepts.Rpayment.unique())

"""Terdapat 615 data restoran yang unik dengan 12 jenis pembayaran yang diterima.

Sebelumnya 1314 entri, setelah difilter dengan fungsi unique() datanya menjadi sejumlah 615.

## Cuisine Variable
"""

cuisine.info()

"""Lihat jumlah tipe masakan (cuisine) dan nama-nama masakannya menggunakan fungsi unique()"""

print('Banyak tipe masakan: ', len(cuisine.Rcuisine.unique()))
print('Tipe masakan: ', cuisine.Rcuisine.unique())

"""Terdapat 59 tipe masakan yang berbeda dengan nama masakan.

Data cuisine akan digunakan untuk memprediksi top-N rekomendasi bagi pengguna.

## Profile

Lihat jumlah kolom dan baris pada variabel profile.
"""

print(profile.shape)

"""Lihat fitur apa saja yang terdapat pada variabel profile."""

profile.head()

"""## Rating

Lihat seperti apa data pada variabel rating dengan fungsi head()
"""

rating.head()

"""Dari fungsi rating.head(), dapat diketahui bahwa data rating terdiri dari 5 kolom dengan tiga kategori rating. Kolom-kolom tersebut antara lain:

- userID, merupakan identitas pengguna.
- placeID, merupakan identitas restoran.
- Rating, merupakan data rating untuk restoran.
- Food_rating, merupakan data rating untuk makanan atau masakan di restoran tersebut.
- Service_rating, merupakan data layanan restoran tersebut.

Lihat distribusi rating pada data menggunakan fungsi describe()
"""

rating.describe()

"""Nilai maksimum rating adalah 2 dan nilai minimumnya adalah 0, yang berarti skala rating berkisar antara 0 hingga 2.

Lihat berapa pengguna yang memberikan rating, jumlah restoran, dan jumlah rating.
"""

print('Jumlah userID: ', len(rating.userID.unique()))
print('Jumlah placeID: ', len(rating.placeID.unique()))
print('Jumlah data rating: ', len(rating))

"""Dari 9 variabel yang ada sementara saya eskplorasi 5 dulu.

# Data Preprocessing

## Menggabungkan restoran

- Identifikasi berapa jumlah seluruh restoran pada dataset. 
- Library numpy dan fungsi concatenate untuk menggabungkan beberapa file. 
- Diketahui sebelumnya bahwa kesembilan file data dibagi ke dalam tiga kategori, yaitu: Restaurant, User, dan Rating. 
- Menggabungkan seluruh data pada kategori Restaurant. Menggunakan placeID yang unik sebagai acuan dalam penggabungan ini.
"""

import numpy as np
 
# Menggabungkan seluruh placeID pada kategori Restaurant
resto_all = np.concatenate((
    accepts.placeID.unique(),
    cuisine.placeID.unique(),
    hours.placeID.unique(),
    parking.placeID.unique(),
    geo.placeID.unique()
))
 
# Mengurutkan data dan menghapus data yang sama
resto_all = np.sort(np.unique(resto_all))
 
print('Jumlah seluruh data restoran berdasarkan placeID: ', len(resto_all))

"""## Menggabungkan seluruh user"""

# Menggabungkan seluruh userID
user_all = np.concatenate((
    usercuisine.userID.unique(),
    payment.userID.unique(),
    profile.userID.unique()
))
 
# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all)) 
 
print('Jumlah seluruh user: ', len(user_all))

"""138 data pengguna dari 938 restoran yang memiliki rating.

## Mengetahui jumlah rating
"""

# Menggabungkan file accepts, geo, parking, hours ke dalam dataframe resto_info 
resto_info = pd.concat([accepts, geo, parking, hours])
 
# Menggabungkan dataframe rating dengan resto_info berdasarkan nilai placeID
resto = pd.merge(rating, resto_info , on='placeID', how='left')
resto

"""## Cek missing value dengan fungsi isnull()"""

resto.isnull().sum()

"""Terdapat banyak missing value pada sebagian besar fitur. Hanya fitur userID, placeID, rating, food_rating, dan service_rating saja yang memiliki 0 missing value. Hitung jumlah rating, food_rating, dan service rating berdasarkan place.ID

## Menghitung jumlah rating, food_rating, dan service kemudian menggabungkannya berdasarkan placeID
"""

resto.groupby('placeID').sum()

"""## Menggabungkan Data dengan Fitur Nama Resto

Definisikan dataframe rating ke dalam variabel all_resto_rate
"""

all_resto_rate = rating
all_resto_rate

"""Untuk mengetahui nama restoran dengan placeID tertentu, gabungkan data geo yang berisikan placeID dan nama resto berdasarkan placeID dan assign ke variabel all_resto_name dengan fungsi merge dari library pandas.

## Menggabungkan all resto_rate dengan dataframe geo berdasarkan placeID
"""

all_resto_name = pd.merge(all_resto_rate, geo[['placeID','name']], on='placeID', how='left')

"""## Print dataframe all_resto_name"""

all_resto_name

"""## Menggabungkan Data dengan Fitur masakan Resto

Menggabungkan dataframe cuisine dengan all_resto_name dan memasukkannya ke dalam variabel all_resto dengan tujuan untuk mengetahui masakan yang disediakan oleh restoran.
"""

all_resto = pd.merge(all_resto_name, cuisine, on='placeID', how='left')
all_resto

"""Dataset inilah digunakan untuk membuat sistem rekomendasi.

# Data Preparation

## Mengatasi missing value

Cek missing value pada dataframe all_resto
"""

all_resto.isnull().sum()

"""Terdapat 288 missing value pada fitur ‘Rcuisine’ (kategori masakan). Walaupun 288 dari 1331 merupakan jumlah yang signifikan, namun tidak bisa mengidentifikasi nama masakan yang tidak memiliki data ‘Rcuisine’ ini termasuk ke dalam kategori masakan mana, sehingga tetap lakukan drop.

## Membersihkan missing value dengan fungsi dropna()
"""

all_resto_clean = all_resto.dropna()
all_resto_clean

"""Data memiliki 1043 baris

## Mengecek kembali missing value pada variabel all_resto_clean
"""

all_resto_clean.isnull().sum()

"""## Menyamakan jenis masakan

Terkadang masakan yang sama memiliki nama atau kategori yang berbeda. Jika dibiarkan dapat menyebabkan bias pada data.

## Mengurutkan resto berdasarkan PlaceID kemudian memasukkannya ke dalam variabel fix_resto
"""

fix_resto = all_resto_clean.sort_values('placeID', ascending=True)
fix_resto

"""## Cek berapa jumlah fix_resto"""

len(fix_resto.placeID.unique())

"""## Cek kategori masakan yang unik"""

fix_resto.Rcuisine.unique()

"""## Cek kategori masakan Game """

fix_resto[fix_resto['Rcuisine'] == 'Game']

"""Game adalah masakan pada nama restoran KFC.

## Mengecek kategori masakan pada nama restoran KFC
"""

fix_resto[fix_resto['name'] == 'KFC']

"""Harus diperbaiki karena dalam sistem ini satu restoran harus hanya memiliki satu kategori masakan, sedangkan KFC memiliki dua kategori masakan yaitu ‘Game’ dan ‘American’.

## Mengubah nama kategori masakan ‘Game’ menjadi ‘American’
"""

fix_resto = fix_resto.replace('Game', 'American')
fix_resto[fix_resto['name'] == 'KFC']

"""Satu restoran mewakili satu kategori masakan dengan tujuan agar tidak terjadi dobel atau rangkap kategori dalam satu restoran. Sehingga, sistem dapat merekomendasikan resto berdasarkan kategori masakannya.

## Membuat variabel preparation yang berisi dataframe fix_resto kemudian mengurutkan berdasarkan placeID
"""

preparation = fix_resto
preparation.sort_values('placeID')

"""Pada proses pemodelan yang dimasukkan hanya data unik. Oleh karena itu, perlu menghapus data yang duplikat dengan fungsi drop_duplicates(). Dalam hal ini, buang data duplikat pada kolom ‘placeID’.

## Membuang data duplikat pada variabel preparation
"""

preparation = preparation.drop_duplicates('placeID')
preparation

"""## Konversi data series menjadi list menggunakan fungsi tolist() dari library numpy."""

# Mengonversi data series ‘placeID’ menjadi dalam bentuk list
resto_id = preparation['placeID'].tolist()
 
# Mengonversi data series ‘Name’ menjadi dalam bentuk list
resto_name = preparation['name'].tolist()
 
# Mengonversi data series ‘Rcuisine’ menjadi dalam bentuk list
resto_cuisine = preparation['Rcuisine'].tolist()
 
print(len(resto_id))
print(len(resto_name))
print(len(resto_cuisine))

"""Membuat dictionary untuk menentukan pasangan key-value pada data resto_id, resto_name, dan resto_cuisine yang telah disiapkan sebelumnya.

## Membuat dictionary untuk data ‘resto_id’, ‘resto_name’, dan ‘cuisine’
"""

resto_new = pd.DataFrame({
    'id': resto_id,
    'resto_name': resto_name,
    'cuisine': resto_cuisine
})
resto_new

"""# Model Development dengan Content Based Filtering

Teknik ini merekomendasikan item yang mirip dengan preferensi pengguna di masa lalu.

Cek lagi data yang dimiliki dan assign dataframe dari tahap sebelumnya ke dalam variabel data.
"""

data = resto_new
data.sample(5)

"""## TF-IDF Vectorizer

Menggunakan fungsi tfidfvectorizer() dari library sklearn.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data cuisine
tf.fit(data['cuisine']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

"""## Fit dan transformasi ke dalam bentuk matriks"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['cuisine']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Matriksberukuran (95, 22). Nilai 95 merupakan ukuran data dan 22 merupakan matrik kategori masakan. 

Untuk menghasilkan vektor tf-idf dalam bentuk matriks, menggunakan fungsi todense().

## Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
"""

tfidf_matrix.todense()

"""Lihat matriks tf-idf untuk beberapa resto (resto_name) dan kategori masakan (cuisine)."""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis masakan
# Baris diisi dengan nama resto
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.resto_name
).sample(22, axis=1).sample(10, axis=0)

"""Output matriks tf-idf menunjukkan Restaurant Bar Fu-hao memiliki kategori bar. Bar Fu-hao, matriks menunjukan bahwa restoran tersebut merupakan resto dengan kategori bar. Hal ini terlihat dari nilai matriks 1.0 pada kategori bar. Restoran El Rincon de San Francisco termasuk dalam kategori mexican. Restoran Tortas y hamburguesas el gordo termasuk dalam kategori burgers. Demikian seterusnya.

Sampai di sini telah berhasil mengidentifikasi representasi fitur penting dari setiap kategori masakan dengan fungsi tfidfvectorizer. Selain itu juga telah menghasilkan matriks yang menunjukkan korelasi antara jenis masakan dengan restoran.

Selanjutnya menghitung derajat kesamaan antara satu restoran dengan restoran lainnya untuk menghasilkan kandidat restoran yang akan direkomendasikan.

## Cosine Similarity

Sebelumnya telah berhasil mengidentifikasi korelasi antara restoran dengan kategori masakannya. Sekarang hitung derajat kesamaan (similarity degree) antar restoran dengan teknik cosine similarity. Gunakan fungsi cosine_similarity dari library sklearn.
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Menghitung cosine similarity dataframe tfidf_matrix yang diperoleh pada tahapan sebelumnya. Dengan satu baris kode untuk memanggil fungsi cosine similarity dari library sklearn, telah berhasil menghitung kesamaan (similarity) antar restoran. Kode di atas menghasilkan keluaran berupa matriks kesamaan dalam bentuk array.

Lihat matriks kesamaan setiap resto dengan menampilkan nama restoran dalam 5 sampel kolom (axis = 1) dan 10 sampel baris (axis=0).

## Buat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['resto_name'], columns=data['resto_name'])
print('Shape:', cosine_sim_df.shape)

"""## Lihat similarity matrix pada setiap resto"""

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dengan cosine similarity, telah berhasil mengidentifikasi kesamaan antara satu restoran dengan restoran lainnya. Shape (95, 95) merupakan ukuran matriks similarity dari data yang dimiliki. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 95 restoran x 95 restoran (masing-masing dalam sumbu X dan Y). Artinya, mengidentifikasi tingkat kesamaan pada 95 nama restoran. Tapi tentu tidak bisa menampilkan semuanya. Oleh karena itu, hanya memilih 10 restoran pada baris vertikal dan 5 restoran pada sumbu horizontal seperti pada contoh di atas.

Angka 1.0 yang diberi kotak merah mengindikasikan bahwa restoran pada kolom X (horizontal) memiliki kesamaan dengan restoran pada baris Y (vertikal). Sebagai contoh, restoran Gorditas Doa Gloria dan Gorditas Dona Tota teridentifikasi sama (similar) dengan restoran Palomo Tec. Contoh lain, restoran La Perica Hamburguesa teridentifikasi mirip dengan restoran El Mundo de La Pasta.

Dengan data kesamaan (similarity) restoran yang diperoleh dari kode sebelumnya, Akan direkomendasikan daftar resto yang mirip (similar) dengan resto yang sebelumnya pernah melayani pengguna.

## Mendapatkan Rekomendasi

Buat fungsi resto_recommendations dengan beberapa parameter:

- Nama_resto : Nama restoran (index kemiripan dataframe).
- Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.
- Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘resto_name’ dan ‘cuisine’.
- k : Banyak rekomendasi yang ingin diberikan.

Definisi sistem rekomendasi yang menyatakan bahwa keluaran sistem ini adalah berupa top-N recommendation. Oleh karena itu, akan diberikan sejumlah rekomendasi restoran pada pengguna yang diatur dalam parameter k.
"""

def resto_recommendations(nama_resto, similarity_data=cosine_sim_df, items=data[['resto_name', 'cuisine']], k=5):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    nama_resto : tipe data string (str)
                Nama Restoran (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai 
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
 
 
    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_resto].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_resto, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Dengan menggunakan argpartition, mengambil sejumlah nilai k tertinggi dari similarity data (dalam kasus ini: dataframe cosine_sim_df). Kemudian, mengambil data dari bobot (tingkat kesamaan) tertinggi ke terendah. Data ini dimasukkan ke dalam variabel closest. Berikutnya, perlu menghapus nama_resto yang yang dicari agar tidak muncul dalam daftar rekomendasi. Dalam kasus ini, nanti akan mencari resto yang mirip dengan KFC, sehingga perlu drop nama_resto KFC agar tidak muncul dalam daftar rekomendasi yang diberikan nanti.

## Menemukan rekomendasi restoran yang mirip dengan KFC
"""

data[data.resto_name.eq('KFC')]

"""## Mendapatkan rekomendasi restoran yang mirip dengan KFC"""

resto_recommendations('KFC')

"""Sistem memberikan rekomendasi 5 nama restoran dengan kategori ‘cuisine’ American dan satu kategori International.

# Model Development dengan Collaborative Filtering

Teknik ini membutuhkan data rating dari user.

## Data Understanding

## Import library
"""

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""## Membaca dataset"""

df = rating
df

"""Data rating memiliki 1161 baris dan 5 kolom.

## Data Preparation

## Persiapan data untuk menyandikan (encode) fitur ‘user’ dan ‘placeID’ ke dalam indeks integer
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['userID'].unique().tolist()
print('list userID: ', user_ids)
 
# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)
 
# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah placeID menjadi list tanpa nilai yang sama
resto_ids = df['placeID'].unique().tolist()
 
# Melakukan proses encoding placeID
resto_to_resto_encoded = {x: i for i, x in enumerate(resto_ids)}
 
# Melakukan proses encoding angka ke placeID
resto_encoded_to_resto = {i: x for i, x in enumerate(resto_ids)}

"""## Petakan userID dan placeID ke dataframe yang berkaitan"""

# Mapping userID ke dataframe user
df['user'] = df['userID'].map(user_to_user_encoded)
 
# Mapping placeID ke dataframe resto
df['resto'] = df['placeID'].map(resto_to_resto_encoded)

"""## Cek beberapa hal dalam data seperti jumlah user, jumlah resto, dan mengubah nilai rating menjadi float"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# Mendapatkan jumlah resto
num_resto = len(resto_encoded_to_resto)
print(num_resto)
 
# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)
 
# Nilai minimum rating
min_rating = min(df['rating'])
 
# Nilai maksimal rating
max_rating = max(df['rating'])
 
print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_resto, min_rating, max_rating
))

"""# Membagi Data untuk Training dan Validasi

##  Mengacak data agar distribusinya menjadi random
"""

df = df.sample(frac=1, random_state=42)
df

"""Bagibagi data train dan validasi dengan komposisi 80:20. Namun sebelumnya, perlu memetakan (mapping) data user dan resto menjadi satu value terlebih dahulu. Lalu, buat rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training. """

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['user', 'resto']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""# Proses Training

Model menghitung skor kecocokan antara pengguna dan resto dengan teknik embedding. Pertama, lakukan proses embedding terhadap data user dan resto. Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan resto. Selain itu, juga dapat menambahkan bias untuk setiap user dan resto. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.

Membuat class RecommenderNet dengan keras Model class. Kode class RecommenderNet ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang kita selesaikan.
"""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_resto = num_resto
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_resto,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.resto_bias = layers.Embedding(num_resto, 1) # layer embedding resto bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    resto_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.resto_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2) 
 
    x = dot_user_resto + user_bias + resto_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""## Lakukan proses compile terhadap model"""

model = RecommenderNet(num_users, num_resto, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation.

## Mulai proses training
"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""# Visualisasi Metrik

Melihat visualisasi proses training, mari kita plot metrik evaluasi dengan matplotlib.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Proses training model cukup smooth dan model konvergen pada epochs sekitar 100. Dari proses ini, diperoleh nilai error akhir sebesar sekitar 0.23 dan error pada data validasi sebesar 0.33. Nilai tersebut cukup bagus untuk sistem rekomendasi.

# Mendapatkan Rekomendasi Resto

Ambil sampel user secara acak dan definisikan variabel resto_not_visited yang merupakan daftar resto yang belum pernah dikunjungi oleh pengguna. Daftar resto_not_visited inilah yang akan menjadi resto yang direkomendasikan. 

Sebelumnya, pengguna telah memberi rating pada beberapa resto yang telah mereka kunjungi. Gunakan rating ini untuk membuat rekomendasi restoran yang mungkin cocok untuk pengguna. Restoran yang akan direkomendasikan tentulah restoran yang belum pernah dikunjungi oleh pengguna. Oleh karena itu, perlu membuat variabel resto_not_visited sebagai daftar restoran untuk direkomendasikan pada pengguna.

Variabel resto_not_visited diperoleh dengan menggunakan operator bitwise (~) pada variabel resto_visited_by_user.
"""

resto_df = resto_new
df = pd.read_csv('rating_final.csv')
 
# Mengambil sample user
user_id = df.userID.sample(1).iloc[0]
resto_visited_by_user = df[df.userID == user_id]
 
# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html 
resto_not_visited = resto_df[~resto_df['id'].isin(resto_visited_by_user.placeID.values)]['id'] 
resto_not_visited = list(
    set(resto_not_visited)
    .intersection(set(resto_to_resto_encoded.keys()))
)
 
resto_not_visited = [[resto_to_resto_encoded.get(x)] for x in resto_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_resto_array = np.hstack(
    ([[user_encoder]] * len(resto_not_visited), resto_not_visited)
)

"""## Gunakan fungsi model.predict() dari library Keras untuk memperoleh rekomendasi restoran"""

ratings = model.predict(user_resto_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_resto_ids = [
    resto_encoded_to_resto.get(resto_not_visited[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Resto with high ratings from user')
print('----' * 8)
 
top_resto_user = (
    resto_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .placeID.values
)
 
resto_df_rows = resto_df[resto_df['id'].isin(top_resto_user)]
for row in resto_df_rows.itertuples():
    print(row.resto_name, ':', row.cuisine)
 
print('----' * 8)
print('Top 10 resto recommendation')
print('----' * 8)
 
recommended_resto = resto_df[resto_df['id'].isin(recommended_resto_ids)]
for row in recommended_resto.itertuples():
    print(row.resto_name, ':', row.cuisine)

"""Dari output tersebut, dapat membandingkan antara Resto with high ratings from user dan Top 10 resto recommendation untuk user. """